

# import library
from collections import Counter
from imblearn.under_sampling import RandomUnderSampler



rus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable
x_rus, y_rus = rus.fit_resample(X_train, y_train)

print('original dataset shape:', Counter(y_train))
print('Resample dataset shape', Counter(y_rus))

# import library
from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state=42)

# fit predictor and target variablex_ros, 
x_ros, y_ros = ros.fit_resample(X_train, y_train)

print('Original dataset shape', Counter(y_train))
print('Resample dataset shape', Counter(y_ros))

# Feature Extraction with RFE
from sklearn.feature_selection import RFE

rfe = RFE(estimator= LogisticRegression(), n_features_to_select=9)
fit = rfe.fit(X, y)
print('Best feature by rfe:',X.columns[rfe.support_])

from sklearn.feature_selection import SelectFromModel
### selector de variables
rf_clf = RandomForestClassifier(n_estimators=200,random_state =123)

# Train the model
rf_clf.fit(X.values,y.values.ravel())

## ordenando  las mejores variables
features = []
for feature in zip(X.columns, rf_clf.feature_importances_):
    features.append(feature)
    
features_Importance = pd.DataFrame(features,columns=['Variables','Gain']).sort_values('Gain', ascending=False)

sfm = SelectFromModel(rf_clf, threshold = 0.05)

# Train the selector
sfm.fit(X, y)

# Print the names of the most important features

variables = []
for feature_list_index in sfm.get_support(indices=True):
    variables.append(X.columns[feature_list_index])
    
features_Importance

variables

##Random Forest
from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
#creamos una funci√≥n que crea el modelo que usaremos cada vez
def run_model(X_train, X_test, y_train, y_test):
    clf_base = RandomForestClassifier(random_state=1)
    clf_base.fit(X_train, y_train)
    return clf_base
 
#ejecutamos el modelo "tal cual"
model = run_model(X_train[variables], X_test[variables], y_train, y_test)
 
#definimos funciona para mostrar los resultados
def mostrar_resultados(y_test, pred_y):
    conf_matrix = confusion_matrix(y_test, pred_y)
    plt.figure(figsize=(12, 12))
    sns.heatmap(conf_matrix ,annot=True, fmt="d");
    plt.title("Confusion matrix")
    plt.ylabel('True class')
    plt.xlabel('Predicted class')
    plt.show()
    print (classification_report(y_test, pred_y))
 
pred_y = model.predict(X_test[variables])
mostrar_resultados(y_test, pred_y)

model_under = run_model(x_rus[variables], X_test[variables], y_rus, y_test)
pred_y = model_under.predict(X_test[variables])
mostrar_resultados(y_test, pred_y)

model_over = run_model(x_ros[variables], X_test[variables], y_ros, y_test)
pred_y = model_over.predict(X_test[variables])
mostrar_resultados(y_test, pred_y)

model_smote = run_model(x_smote[variables], X_test[variables], y_smote, y_test)
pred_y = model_smote.predict(X_test[variables])
mostrar_resultados(y_test, pred_y)

